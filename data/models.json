[
  {
    "model_id": "microsoft/phi-1",
    "params_b": 1.3,
    "layers": 24,
    "hidden": 2048,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "stabilityai/stablelm-2-zephyr-1_6b",
    "params_b": 1.6,
    "layers": 24,
    "hidden": 2048,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "microsoft/phi-2",
    "params_b": 2.7,
    "layers": 32,
    "hidden": 2560,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "microsoft/phi-3-mini-128k-instruct",
    "params_b": 3.8,
    "layers": 32,
    "hidden": 3072,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "stabilityai/stablelm-zephyr-3b",
    "params_b": 3.0,
    "layers": 32,
    "hidden": 2560,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "EleutherAI/gpt-j-6B",
    "params_b": 6.0,
    "layers": 28,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "mosaicml/mpt-7b",
    "params_b": 7.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "microsoft/Phi-3-small-8k-instruct",
    "params_b": 7.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "meta-llama/Llama-2-7b-hf",
    "params_b": 7.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "tiiuae/falcon-7b",
    "params_b": 7.0,
    "layers": 32,
    "hidden": 4544,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "mistralai/Mistral-7B-v0.1",
    "params_b": 7.3,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "google/gemma-7b",
    "params_b": 7.0,
    "layers": 28,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "mistralai/Mixtral-8x7B",
    "params_b": 56.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.23
  },
  {
    "model_id": "meta-llama/Meta-Llama-3-8B",
    "params_b": 8.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "meta-llama/Llama-2-13b-hf",
    "params_b": 13.0,
    "layers": 40,
    "hidden": 5120,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "microsoft/phi-4",
    "params_b": 14.0,
    "layers": 40,
    "hidden": 5120,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "EleutherAI/gpt-neox-20b",
    "params_b": 20.0,
    "layers": 44,
    "hidden": 6144,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "mosaicml/mpt-30b",
    "params_b": 30.0,
    "layers": 48,
    "hidden": 7168,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "microsoft/Phi-3.5-MoE-instruct",
    "params_b": 61.0,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0.125
  },
  {
    "model_id": "meta-llama/Meta-Llama-3-70B",
    "params_b": 70.0,
    "layers": 80,
    "hidden": 8192,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "meta-llama/Llama-2-70b-hf",
    "params_b": 70.0,
    "layers": 80,
    "hidden": 8192,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "tiiuae/falcon-180B",
    "params_b": 180.0,
    "layers": 120,
    "hidden": 12288,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "THUDM/GLM-130B",
    "params_b": 130.0,
    "layers": 70,
    "hidden": 12288,
    "moe_active_ratio": 0.0
  },
  {
    "model_id": "bigscience/bloom",
    "params_b": 176.0,
    "layers": 70,
    "hidden": 14336,
    "moe_active_ratio": 0.0
  }
]