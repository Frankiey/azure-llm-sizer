[
  {
    "model_id": "microsoft/phi-4",
    "params_b": 14,
    "layers": 40,
    "hidden": 5120,
    "moe_active_ratio": 0
  },
  {
    "model_id": "meta-llama/Llama-3.2-3B-Instruct",
    "params_b": 3,
    "layers": 28,
    "hidden": 2560,
    "moe_active_ratio": 0
  },
  {
    "model_id": "meta-llama/Llama-4-middle",
    "params_b": 40,
    "layers": 48,
    "hidden": 8192,
    "moe_active_ratio": 0
  },
  {
    "model_id": "mistralai/Mistral-Large-Instruct",
    "params_b": 8,
    "layers": 32,
    "hidden": 4096,
    "moe_active_ratio": 0
  }
]
