[
  {"model_id": "microsoft/phi-1", "params_b": 1.3, "layers": 24, "hidden": 2048, "moe_active_ratio": 0},
  {"model_id": "microsoft/phi-2", "params_b": 2.7, "layers": 32, "hidden": 2560, "moe_active_ratio": 0},
  {"model_id": "EleutherAI/gpt-j-6B", "params_b": 6, "layers": 28, "hidden": 4096, "moe_active_ratio": 0},
  {"model_id": "mosaicml/mpt-7b", "params_b": 7, "layers": 32, "hidden": 4096, "moe_active_ratio": 0},
  {"model_id": "microsoft/Phi-3-small-8k-instruct", "params_b": 7, "layers": 32, "hidden": 4096, "moe_active_ratio": 0},
  {"model_id": "meta-llama/Llama-2-7b-hf", "params_b": 7, "layers": 32, "hidden": 4096, "moe_active_ratio": 0},
  {"model_id": "tiiuae/falcon-7b", "params_b": 7, "layers": 32, "hidden": 4544, "moe_active_ratio": 0},
  {"model_id": "mistralai/Mistral-7B-v0.1", "params_b": 7.3, "layers": 32, "hidden": 4096, "moe_active_ratio": 0},
  {"model_id": "meta-llama/Llama-2-13b-hf", "params_b": 13, "layers": 40, "hidden": 5120, "moe_active_ratio": 0},
  {"model_id": "microsoft/phi-4", "params_b": 14, "layers": 40, "hidden": 5120, "moe_active_ratio": 0},
  {"model_id": "EleutherAI/gpt-neox-20b", "params_b": 20, "layers": 44, "hidden": 6144, "moe_active_ratio": 0},
  {"model_id": "mosaicml/mpt-30b", "params_b": 30, "layers": 48, "hidden": 7168, "moe_active_ratio": 0},
  {"model_id": "microsoft/Phi-3.5-MoE-instruct", "params_b": 61, "layers": 32, "hidden": 4096, "moe_active_ratio": 0.125},
  {"model_id": "meta-llama/Llama-2-70b-hf", "params_b": 70, "layers": 80, "hidden": 8192, "moe_active_ratio": 0},
  {"model_id": "THUDM/GLM-130B", "params_b": 130, "layers": 70, "hidden": 12288, "moe_active_ratio": 0},
  {"model_id": "bigscience/bloom", "params_b": 176, "layers": 70, "hidden": 14336, "moe_active_ratio": 0}
]
